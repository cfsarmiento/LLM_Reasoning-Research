{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70577418",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Simple RAG Implementation\n",
    "Author: Christian Sarmiento\n",
    "Purpose: This notebook is intended to get a simple implementation of RAG set up with LangChain.\n",
    "Date Created: 10/1/24\n",
    "Last Updated: 11/17/24\n",
    "Data: https://archive.ics.uci.edu/dataset/450/sports+articles+for+objectivity+analysis\n",
    "Sources:\n",
    "- https://python.langchain.com/docs/tutorials/rag/\n",
    "- https://python.langchain.com/docs/tutorials/llm_chain/\n",
    "- https://medium.com/@dinabavli/rag-basics-basic-implementation-of-retrieval-augmented-generation-rag-e80e0791159d\n",
    "- ChatGPT: o1-preview\n",
    "-----------------------------------------------------------------------------------------------------------------------\n",
    "RAG Research             |               Machine Learning Independent Study             |              DR. EITEL LAURIA\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db84d629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ragas in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (0.2.3)\n",
      "Requirement already satisfied: numpy in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from ragas) (1.26.4)\n",
      "Requirement already satisfied: datasets in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from ragas) (3.1.0)\n",
      "Requirement already satisfied: tiktoken in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from ragas) (0.7.0)\n",
      "Requirement already satisfied: langchain in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from ragas) (0.3.1)\n",
      "Requirement already satisfied: langchain-core in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from ragas) (0.3.6)\n",
      "Requirement already satisfied: langchain-community in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from ragas) (0.3.1)\n",
      "Requirement already satisfied: langchain-openai in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from ragas) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from ragas) (1.6.0)\n",
      "Requirement already satisfied: appdirs in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from ragas) (1.4.4)\n",
      "Requirement already satisfied: pydantic>=2 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from ragas) (2.9.2)\n",
      "Requirement already satisfied: openai>1 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from ragas) (1.50.0)\n",
      "Requirement already satisfied: pysbd>=0.3.4 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from ragas) (0.3.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from openai>1->ragas) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from openai>1->ragas) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from openai>1->ragas) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from openai>1->ragas) (0.5.0)\n",
      "Requirement already satisfied: sniffio in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from openai>1->ragas) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from openai>1->ragas) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from openai>1->ragas) (4.11.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from pydantic>=2->ragas) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from pydantic>=2->ragas) (2.23.4)\n",
      "Requirement already satisfied: filelock in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from datasets->ragas) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from datasets->ragas) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from datasets->ragas) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from datasets->ragas) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from datasets->ragas) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from datasets->ragas) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from datasets->ragas) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->ragas) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from datasets->ragas) (3.10.6)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from datasets->ragas) (0.25.1)\n",
      "Requirement already satisfied: packaging in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from datasets->ragas) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from datasets->ragas) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from langchain->ragas) (2.0.35)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from langchain->ragas) (0.3.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from langchain->ragas) (0.1.129)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from langchain->ragas) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from langchain-core->ragas) (1.33)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from langchain-community->ragas) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from langchain-community->ragas) (2.5.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from tiktoken->ragas) (2024.9.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from aiohttp->datasets->ragas) (2.4.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from aiohttp->datasets->ragas) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from aiohttp->datasets->ragas) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from aiohttp->datasets->ragas) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from aiohttp->datasets->ragas) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from aiohttp->datasets->ragas) (1.13.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai>1->ragas) (3.10)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (0.9.0)\n",
      "Requirement already satisfied: certifi in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai>1->ragas) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai>1->ragas) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->ragas) (3.10.7)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->ragas) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from requests>=2.32.2->datasets->ragas) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from requests>=2.32.2->datasets->ragas) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain->ragas) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from pandas->datasets->ragas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from pandas->datasets->ragas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from pandas->datasets->ragas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nltk in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages (from nltk) (4.66.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Download RAGAS for RAG metrics\n",
    "%pip install ragas\n",
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f6dfada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append(\"/Users/christiansarmiento/Library/CloudStorage/OneDrive-MaristCollege/Machine Learning/Private Code\")\n",
    "from api_keys import openAIKey\n",
    "from api_keys import langchainKey\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplittermjm\n",
    "import pandas as pd\n",
    "import os\n",
    "import gradio as gr  # easy frontend implementation\n",
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, SemanticSimilarity\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas import SingleTurnSample, EvaluationDataset\n",
    "from ragas import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6cc71a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain Enviornment Variables\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = langchainKey()\n",
    "os.environ[\"OPENAI_API_KEY\"] = openAIKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99387228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OpenAI model with metric wrapper\n",
    "#llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
    "#evalEmbeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5b23c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics\n",
    "metrics = [LLMContextRecall(llm=llm), FactualCorrectness(llm=llm), Faithfulness(llm=llm), SemanticSimilarity(embeddings=evalEmbeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc182a12-6a70-4fb9-8f77-823e341f989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "folderPath = \"/Users/christiansarmiento/Library/CloudStorage/OneDrive-MaristCollege/Machine Learning/Data/sports_articles_corpus/Raw data\"\n",
    "sportsArticles = []\n",
    "\n",
    "for fileName in os.listdir(folderPath):\n",
    "    filePath = os.path.join(folderPath, fileName)\n",
    "    loader = TextLoader(filePath, encoding='latin1')  # UTF-8 not working for the files\n",
    "    doc = loader.load()\n",
    "    sportsArticles.extend(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c567c173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Documents into Chunks\n",
    "textSplitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, add_start_index=True)\n",
    "texts = textSplitter.split_documents(sportsArticles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2646002f-c802-441e-bd43-adb3bb76c2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Documents in Vector DB (Chroma)\n",
    "vectorDB = Chroma.from_documents(documents=texts, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac4c8790-f634-40b7-9d96-841c65f5f9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Retrieval System\n",
    "retriever = vectorDB.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})  # Retrieves 3 documents\n",
    "\n",
    "# To get retrieved documents:\n",
    "# retrievedDocuments = retriever.invoke(\"query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1f6b342-08b9-4e63-b946-280e3590ac85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the RAG Chain\n",
    "\n",
    "# Function to format documents into the prompt\n",
    "def formatDocs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Setup RAG Chain\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "ragChain = (\n",
    "    {\"context\": retriever | formatDocs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24e7ebd5-e639-491d-aaaf-636cd788b166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The offside rule in soccer states that a player is in an offside position if they are nearer to the opponent's goal line than both the ball and the second-to-last opponent when the ball is played to them, unless they are in their own half or level with the second-to-last opponent. Being in an offside position is not an offense in itself; the player must become involved in active play to be penalized. The rule aims to prevent players from gaining an unfair advantage by lingering near the opponent's goal."
     ]
    }
   ],
   "source": [
    "# Results\n",
    "for chunk in ragChain.stream(\"Explain the offside rule in soccer.\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f88a596-3c50-43af-9ca5-bcb13feb4570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if answers are coming from the llm or from the documents\n",
    "# Try giving documents that aren't real then asking questions on things off of that\n",
    "# Avoids the model relying on trained info \n",
    "# Play with the system prompt\n",
    "\n",
    "# Next step after QA - feed answers into the system to make it more conversational\n",
    "# Implement Gradio\n",
    "# Knowledge Graph \n",
    "# Identifying Metrics - do research!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d5d2da-5ee6-4dd7-8008-8ee8a751d297",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Implement with Marist Data\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49d2eaa0-434f-409a-8299-d94c24d4f207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "csvPath = \"/Users/christiansarmiento/Library/CloudStorage/OneDrive-MaristCollege/Machine Learning/Data/Marist_QA.csv\"\n",
    "maristQA = pd.read_csv(csvPath, header=None)\n",
    "\n",
    "# To use RecursiveCharacterTextSplitter, we need a list of dictionaries\n",
    "maristContext = [Document(page_content=text) for text in maristQA[1].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e06dbe67-e698-4083-8998-370ff78fc21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Documents into Chunks\n",
    "textSplitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, add_start_index=True)\n",
    "texts = textSplitter.split_documents(maristContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7dac6137-0ecf-4c22-9c6a-ec8c86c6a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Documents in Vector DB (Chroma)\n",
    "vectorDB = Chroma.from_documents(documents=texts, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7cfc0f3a-3933-4dd7-8558-d9b240a83e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Retrieval System\n",
    "retriever = vectorDB.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})  # Retrieves 3 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd26cb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts\n",
    "systemPrompt = (\n",
    "    \n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    "    \n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    \n",
    "    [\n",
    "        (\"system\", systemPrompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    "    \n",
    ")\n",
    "\n",
    "contextualizeSystemPrompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, \"\n",
    "    \"just reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "contextualizePrompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualizeSystemPrompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "historyAwareRetriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualizePrompt\n",
    ")\n",
    "\n",
    "qaPrompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", systemPrompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7dad046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make chains\n",
    "questionAnswerChain = create_stuff_documents_chain(llm, qaPrompt)\n",
    "ragChain = create_retrieval_chain(historyAwareRetriever, questionAnswerChain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e91b900d-6610-46a6-be4b-4c76a99e70f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marist College is located on the banks of the Hudson River and also has a campus in Florence, Italy.\n",
      "\n",
      "Marist College is in Poughkeepsie, New York, situated along the Hudson River. The Florence campus is located in Florence, Italy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Talking to ChatGPT, making RAG conversational\n",
    "conversationHistory = []\n",
    "userQuery = input(\"Prompt (0 to quit): \")\n",
    "while userQuery != '0':\n",
    "\n",
    "    # Print input - this is just for a VSCode enviornment to see I/O together, feel free to comment out in Jupyter\n",
    "    print(f\"User: {userQuery}\")\n",
    "\n",
    "    # Call ChatGPT using RAG chain\n",
    "    llmResponse = ragChain.invoke({\"input\": userQuery, \"chat_history\": conversationHistory})\n",
    "    print(f\"LLM: {llmResponse['answer']}\")\n",
    "    print()\n",
    "    conversationHistory.extend([\n",
    "        \n",
    "        HumanMessage(content=userQuery),\n",
    "        AIMessage(content=llmResponse[\"answer\"]),\n",
    "        \n",
    "    ])\n",
    "\n",
    "    # New prompt\n",
    "    userQuery = input(\"Prompt (0 to quit): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39c79824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages/gradio/components/chatbot.py:222: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frontend with Gradio\n",
    "\n",
    "'''\n",
    "Function that calls the RAG chain for Gradio\n",
    "'''\n",
    "evaluationSamples = []\n",
    "def simpleRAG(userQuery, history, correctAnswer):\n",
    "\n",
    "    # Ensure there is a list to use for the conversation history\n",
    "    if history is None:\n",
    "        history = []\n",
    "\n",
    "    # Call ChatGPT using RAG chain\n",
    "    llmResponse = ragChain.invoke({\"input\": userQuery, \"chat_history\": history})\n",
    "\n",
    "    # Get response and context for evaluation\n",
    "    responseText = llmResponse[\"answer\"]\n",
    "    retrievedContexts = [context.page_content for context in retriever.get_relevant_documents(userQuery)]\n",
    "\n",
    "    # Save information for RAG metrics\n",
    "    evaluationSamples.append({\n",
    "        \"user_input\": userQuery,\n",
    "        \"retrieved_contexts\": retrievedContexts,\n",
    "        \"response\": responseText,\n",
    "        \"reference\": correctAnswer  \n",
    "    })\n",
    "\n",
    "    # Save chat history for conversational aspect\n",
    "    history.extend([\n",
    "        \n",
    "        HumanMessage(content=userQuery),\n",
    "        AIMessage(content=llmResponse[\"answer\"]),\n",
    "        \n",
    "    ])\n",
    "\n",
    "    # Save input and output to history\n",
    "    history.append(HumanMessage(content=userQuery))\n",
    "    history.append(AIMessage(content=llmResponse[\"answer\"]))\n",
    "\n",
    "    # Prepare display of data\n",
    "    chatDisplay = [(msg.content, \"User\" if isinstance(msg, HumanMessage) else \"LLM\") for msg in history]\n",
    "\n",
    "    return chatDisplay, history\n",
    "\n",
    "# Frontend\n",
    "interface = gr.Interface(\n",
    "    fn=simpleRAG,  \n",
    "    inputs=[\"text\", \"state\", gr.Textbox(label=\"Correct Answer\")],  \n",
    "    outputs=[\"chatbot\", \"state\"],  \n",
    "    title=\"Simple RAG\",  \n",
    "    description=\"Initial setup for a simple conversational RAG process.\"\n",
    ")\n",
    "\n",
    "# Launch the frontend\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e5e26f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation dataset for RAG chain evaluation\n",
    "def createEvaluationDataset():\n",
    "\n",
    "    # Create samples\n",
    "    samples = [\n",
    "        SingleTurnSample(\n",
    "            user_input=sample[\"user_input\"],\n",
    "            retrieved_contexts=sample[\"retrieved_contexts\"],\n",
    "            response=sample[\"response\"],\n",
    "            reference=sample[\"reference\"]\n",
    "        )\n",
    "        for sample in evaluationSamples\n",
    "    ]\n",
    "\n",
    "    return EvaluationDataset(samples=samples)\n",
    "\n",
    "evaluationDataset = createEvaluationDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "377d831a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  21%|██        | 5/24 [00:02<00:07,  2.65it/s]The LLM did not return a valid classification.\n",
      "Evaluating:  79%|███████▉  | 19/24 [00:13<00:03,  1.31it/s]Exception raised in Job[5]: TypeError(ufunc 'invert' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe'')\n",
      "Evaluating: 100%|██████████| 24/24 [00:22<00:00,  1.08it/s]\n",
      "/Users/christiansarmiento/opt/anaconda3/envs/LLM-LangChain/lib/python3.12/site-packages/pydantic/main.py:390: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `dict[str, any]` but got `EvaluationResult` with value `{'context_recall': 0.0000...tic_similarity': 0.8868}` - serialized value may not be as expected\n",
      "  Expected `dict[str, any]` but got `EvaluationResult` with value `{'context_recall': 0.0000...tic_similarity': 0.8868}` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>factual_correctness</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>semantic_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is Carolyn Matheus?</td>\n",
       "      <td>[Excellence in Teaching. Dr. Carolyn C. Matheu...</td>\n",
       "      <td>Dr. Carolyn C. Matheus is an Associate Profess...</td>\n",
       "      <td>Carolyn Matheus is a faculty member in the Sch...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.934487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who is Carolyn Matheus</td>\n",
       "      <td>[Excellence in Teaching. Dr. Carolyn C. Matheu...</td>\n",
       "      <td>Dr. Carolyn C. Matheus is an Associate Profess...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.692713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who is Carolyn Matheus?</td>\n",
       "      <td>[Excellence in Teaching. Dr. Carolyn C. Matheu...</td>\n",
       "      <td>Dr. Carolyn C. Matheus is an Associate Profess...</td>\n",
       "      <td>Carolyn Matheus is a faculty member for the Sc...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.935721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Where degrees does she hold?</td>\n",
       "      <td>[Administration from LeMoyne College, and her ...</td>\n",
       "      <td>Dr. Carolyn C. Matheus holds undergraduate and...</td>\n",
       "      <td>Carolyn Matheus has a BA and MA in Psychology ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.963033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who is Carolyn Matheus</td>\n",
       "      <td>[Excellence in Teaching. Dr. Carolyn C. Matheu...</td>\n",
       "      <td>Dr. Carolyn C. Matheus is an Associate Profess...</td>\n",
       "      <td>Carolyn Matheus is a professor in the school o...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.927859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     user_input  \\\n",
       "0       Who is Carolyn Matheus?   \n",
       "1        Who is Carolyn Matheus   \n",
       "2       Who is Carolyn Matheus?   \n",
       "3  Where degrees does she hold?   \n",
       "4        Who is Carolyn Matheus   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [Excellence in Teaching. Dr. Carolyn C. Matheu...   \n",
       "1  [Excellence in Teaching. Dr. Carolyn C. Matheu...   \n",
       "2  [Excellence in Teaching. Dr. Carolyn C. Matheu...   \n",
       "3  [Administration from LeMoyne College, and her ...   \n",
       "4  [Excellence in Teaching. Dr. Carolyn C. Matheu...   \n",
       "\n",
       "                                            response  \\\n",
       "0  Dr. Carolyn C. Matheus is an Associate Profess...   \n",
       "1  Dr. Carolyn C. Matheus is an Associate Profess...   \n",
       "2  Dr. Carolyn C. Matheus is an Associate Profess...   \n",
       "3  Dr. Carolyn C. Matheus holds undergraduate and...   \n",
       "4  Dr. Carolyn C. Matheus is an Associate Profess...   \n",
       "\n",
       "                                           reference  context_recall  \\\n",
       "0  Carolyn Matheus is a faculty member in the Sch...             0.0   \n",
       "1                                                                NaN   \n",
       "2  Carolyn Matheus is a faculty member for the Sc...             0.0   \n",
       "3  Carolyn Matheus has a BA and MA in Psychology ...             0.0   \n",
       "4  Carolyn Matheus is a professor in the school o...             0.0   \n",
       "\n",
       "   factual_correctness  faithfulness  semantic_similarity  \n",
       "0                 0.00           1.0             0.934487  \n",
       "1                  NaN           1.0             0.692713  \n",
       "2                 0.00           1.0             0.935721  \n",
       "3                 0.73           0.0             0.963033  \n",
       "4                 0.00           1.0             0.927859  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run and save evaluation\n",
    "results = evaluate(dataset=evaluationDataset, metrics=metrics)\n",
    "evaluations = results.to_pandas()\n",
    "evaluations.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
